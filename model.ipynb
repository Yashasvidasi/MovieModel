{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Project \n",
    "#### by Cosine similarity (content-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Proccessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Importing modules, reading data and deleting duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('movies.csv')\n",
    "data = data.drop_duplicates()\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Drop null values with no title/overview/release_date/poster_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['title', 'overview', 'release_date', 'poster_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keeping only Released and non pornographic content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['status'] == 'Released']\n",
    "data = data[data['adult'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing column which will have no impact on the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.drop(['homepage', 'status', 'backdrop_path', 'imdb_id', 'original_title', 'popularity'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling important columns which will affect the vectors, will empty string instead of null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['genres'] = data['genres'].fillna(\"\")\n",
    "data['tagline'] = data['tagline'].fillna(\"\")\n",
    "data['production_companies'] = data['production_companies'].fillna(\"\")\n",
    "data['production_countries'] = data['production_countries'].fillna(\"\")\n",
    "data['spoken_languages'] = data['spoken_languages'].fillna(\"\")\n",
    "data['keywords'] = data['keywords'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking Null values if they are present still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "title                   0\n",
       "vote_average            0\n",
       "vote_count              0\n",
       "release_date            0\n",
       "revenue                 0\n",
       "runtime                 0\n",
       "adult                   0\n",
       "budget                  0\n",
       "original_language       0\n",
       "overview                0\n",
       "poster_path             0\n",
       "tagline                 0\n",
       "genres                  0\n",
       "production_companies    0\n",
       "production_countries    0\n",
       "spoken_languages        0\n",
       "keywords                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the copy of top 15000 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15000 entries, 0 to 15070\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    15000 non-null  int64  \n",
      " 1   title                 15000 non-null  object \n",
      " 2   vote_average          15000 non-null  float64\n",
      " 3   vote_count            15000 non-null  int64  \n",
      " 4   release_date          15000 non-null  object \n",
      " 5   revenue               15000 non-null  int64  \n",
      " 6   runtime               15000 non-null  int64  \n",
      " 7   adult                 15000 non-null  bool   \n",
      " 8   budget                15000 non-null  int64  \n",
      " 9   original_language     15000 non-null  object \n",
      " 10  overview              15000 non-null  object \n",
      " 11  poster_path           15000 non-null  object \n",
      " 12  tagline               15000 non-null  object \n",
      " 13  genres                15000 non-null  object \n",
      " 14  production_companies  15000 non-null  object \n",
      " 15  production_countries  15000 non-null  object \n",
      " 16  spoken_languages      15000 non-null  object \n",
      " 17  keywords              15000 non-null  object \n",
      "dtypes: bool(1), float64(1), int64(5), object(11)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_sorted = data.sort_values(by='vote_count', ascending=False) #first 15000 popular movies\n",
    "data = data_sorted.iloc[:15000].copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting sentences to list of words and removing special characters and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#removing spaces\n",
    "data[\"genres\"] = data[\"genres\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"tagline\"] = data[\"tagline\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"production_companies\"] = data[\"production_companies\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"production_countries\"] = data[\"production_countries\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"spoken_languages\"] = data[\"spoken_languages\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"keywords\"] = data[\"keywords\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "\n",
    "#spliting by ',' to create list and storing it in dataframe again\n",
    "data[\"genres\"] = data[\"genres\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"tagline\"] = data[\"tagline\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"production_companies\"] = data[\"production_companies\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"production_countries\"] = data[\"production_countries\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"spoken_languages\"] = data[\"spoken_languages\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"keywords\"] = data[\"keywords\"].apply(lambda x: x.split(\",\"))\n",
    "data['overview'] = data['overview'].str.replace(r'[,.!?\"]', '', regex=True)\n",
    "data[\"overview\"] = data[\"overview\"].apply(lambda x: x.split())\n",
    "\n",
    "data[\"release_date\"] = data[\"release_date\"].apply(lambda x: int(x[0:4]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using min-max scaling to scale between 0 and 1\n",
    "data['vote_average'] = (data['vote_average'] - data['vote_average'].min()) / (data['vote_average'].max() - data['vote_average'].min())\n",
    "data['vote_count'] = (data['vote_count'] - data['vote_count'].min()) / (data['vote_count'].max() - data['vote_count'].min())\n",
    "data['release_date'] = (data['release_date'] - data['release_date'].min()) / (data['release_date'].max() - data['release_date'].min())\n",
    "data['revenue'] = (data['revenue'] - data['revenue'].min()) / (data['revenue'].max() - data['revenue'].min())\n",
    "data['runtime'] = (data['runtime'] - data['runtime'].min()) / (data['runtime'].max() - data['runtime'].min())\n",
    "data['budget'] = (data['budget'] - data['budget'].min()) / (data['budget'].max() - data['budget'].min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting singular value coluns to list too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"original_language\"] = data[\"original_language\"].apply(lambda x: [x])\n",
    "data[\"adult\"] = data[\"adult\"].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new Column 'tags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tags\"] = data[\"overview\"]+data[\"genres\"]+data[\"tagline\"]+data[\"production_companies\"]+data[\"production_countries\"]+data[\"spoken_languages\"]+data[\"keywords\"]+data[\"original_language\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking a random Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                 387399\n",
       "title                                                            We Go On\n",
       "vote_average                                                      0.51859\n",
       "vote_count                                                            0.0\n",
       "release_date                                                     0.948148\n",
       "revenue                                                               0.0\n",
       "runtime                                                          0.152659\n",
       "adult                                                             [False]\n",
       "budget                                                                0.0\n",
       "original_language                                                    [en]\n",
       "overview                [Paralyzed, by, his, fear, of, dying, Miles, G...\n",
       "poster_path                              /dBk6ol8q7kzlU2o7C5LmNmIXCQP.jpg\n",
       "tagline                                   [Somedoorsshouldneverbeopened.]\n",
       "genres                                          [Drama, Horror, Thriller]\n",
       "production_companies                                  [FilmedImagination]\n",
       "production_countries                              [UnitedStatesofAmerica]\n",
       "spoken_languages                                                [English]\n",
       "keywords                [medium, haunting, murder, ghost, fearofdeath,...\n",
       "tags                    [Paralyzed, by, his, fear, of, dying, Miles, G...\n",
       "Name: 15069, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns which were used in making tags column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['keywords', 'adult', 'original_language', 'overview', 'genres'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15000 entries, 0 to 15070\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    15000 non-null  int64  \n",
      " 1   title                 15000 non-null  object \n",
      " 2   vote_average          15000 non-null  float64\n",
      " 3   vote_count            15000 non-null  float64\n",
      " 4   release_date          15000 non-null  float64\n",
      " 5   revenue               15000 non-null  float64\n",
      " 6   runtime               15000 non-null  float64\n",
      " 7   budget                15000 non-null  float64\n",
      " 8   poster_path           15000 non-null  object \n",
      " 9   tagline               15000 non-null  object \n",
      " 10  production_companies  15000 non-null  object \n",
      " 11  production_countries  15000 non-null  object \n",
      " 12  spoken_languages      15000 non-null  object \n",
      " 13  tags                  15000 non-null  object \n",
      "dtypes: float64(6), int64(1), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting tags from list to string and converting it to all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tags\"] = data[\"tags\"].apply(lambda x: \" \".join(x))\n",
    "data[\"tags\"] = data[\"tags\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using stem to convert words with same parent noun, as the same word\n",
    "#### Eg. [Loved, Loves, Loving] will be converted to Love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tags\"]=data[\"tags\"].apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing using Term Frequency - Inverse Document Frequency to calculate word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "#additional columns which will help sorting better movies from the similar movies\n",
    "addon = data[['release_date','runtime', 'vote_average', 'revenue']]\n",
    "\n",
    "#a total of 14000 words frequency to be calculated, stop words such as [the, is, are] are ignored\n",
    "tfidf = TfidfVectorizer(max_features=14000, stop_words='english')\n",
    "vec = tfidf.fit_transform(data['tags'])\n",
    "\n",
    "#combining the matrix\n",
    "combined_matrix = hstack([vec, addon])\n",
    "combined_matrix = combined_matrix.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 14004)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similarity matrix using cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim = cosine_similarity(combined_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the similarity matrix into a CSV file after sorting the rows in descending order and find top 20 similar movie indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open a new CSV file in write mode with UTF-8 encoding\n",
    "with open('sorted_lists.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    for a in sim:\n",
    "       \n",
    "        ml = sorted(list(enumerate(a)), reverse=True, key=lambda x: x[1])[1:21]\n",
    "\n",
    "        row = [index for index, similarity in ml]\n",
    "        \n",
    "        writer.writerow(row)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing Index into a CSV for accessing id, title, poster from the index, stored in similarity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['id','title','poster_path']].to_csv('movieindex.csv',index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Shows Recommendation Project \n",
    "#### by Cosine similarity (content-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Proccessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Importing modules, reading data and deleting duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('tv.csv')\n",
    "data = data.drop_duplicates()\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Drop null values with no title/overview/release_date/poster_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['name', 'overview', 'poster_path', 'first_air_date', 'last_air_date', 'origin_country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keeping only non pornographic content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data[data['adult'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing column which will have no impact on the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.drop(['homepage', 'networks', 'status', 'backdrop_path', 'episode_run_time', 'original_name', 'number_of_seasons', 'number_of_episodes', 'in_production', 'popularity'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling important columns which will affect the vectors, will empty string instead of null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres'] = data['genres'].fillna(\"\")\n",
    "data['tagline'] = data['tagline'].fillna(\"\")\n",
    "data['languages'] = data['languages'].fillna(\"\")\n",
    "data['created_by'] = data['created_by'].fillna(\"\")\n",
    "data['production_companies'] = data['production_companies'].fillna(\"\")\n",
    "data['production_countries'] = data['production_countries'].fillna(\"\")\n",
    "data['spoken_languages'] = data['spoken_languages'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking Null values if they are present still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "name                    0\n",
       "original_language       0\n",
       "vote_count              0\n",
       "vote_average            0\n",
       "overview                0\n",
       "adult                   0\n",
       "first_air_date          0\n",
       "last_air_date           0\n",
       "poster_path             0\n",
       "type                    0\n",
       "tagline                 0\n",
       "genres                  0\n",
       "created_by              0\n",
       "languages               0\n",
       "origin_country          0\n",
       "spoken_languages        0\n",
       "production_companies    0\n",
       "production_countries    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the copy of top 15000 Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15000 entries, 0 to 15580\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    15000 non-null  int64  \n",
      " 1   name                  15000 non-null  object \n",
      " 2   original_language     15000 non-null  object \n",
      " 3   vote_count            15000 non-null  int64  \n",
      " 4   vote_average          15000 non-null  float64\n",
      " 5   overview              15000 non-null  object \n",
      " 6   adult                 15000 non-null  bool   \n",
      " 7   first_air_date        15000 non-null  object \n",
      " 8   last_air_date         15000 non-null  object \n",
      " 9   poster_path           15000 non-null  object \n",
      " 10  type                  15000 non-null  object \n",
      " 11  tagline               15000 non-null  object \n",
      " 12  genres                15000 non-null  object \n",
      " 13  created_by            15000 non-null  object \n",
      " 14  languages             15000 non-null  object \n",
      " 15  origin_country        15000 non-null  object \n",
      " 16  spoken_languages      15000 non-null  object \n",
      " 17  production_companies  15000 non-null  object \n",
      " 18  production_countries  15000 non-null  object \n",
      "dtypes: bool(1), float64(1), int64(2), object(15)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_sorted = data.sort_values(by='vote_count', ascending=False)\n",
    "data = data_sorted.iloc[:15000].copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting sentences to list of words and removing special characters and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing spaces\n",
    "data[\"genres\"] = data[\"genres\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"tagline\"] = data[\"tagline\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"production_companies\"] = data[\"production_companies\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"production_countries\"] = data[\"production_countries\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data[\"spoken_languages\"] = data[\"spoken_languages\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data['languages'] = data['languages'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "data['created_by'] = data['created_by'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "#spliting by ',' to create list and storing it in dataframe again\n",
    "data[\"genres\"] = data[\"genres\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"tagline\"] = data[\"tagline\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"production_companies\"] = data[\"production_companies\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"production_countries\"] = data[\"production_countries\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"spoken_languages\"] = data[\"spoken_languages\"].apply(lambda x: x.split(\",\"))\n",
    "data['languages'] = data['languages'].apply(lambda x: x.split(\",\"))\n",
    "data['created_by'] = data['created_by'].apply(lambda x: x.split(\",\"))\n",
    "data['overview'] = data['overview'].str.replace(r'[,.!?\"]', '', regex=True)\n",
    "data[\"overview\"] = data[\"overview\"].apply(lambda x: x.split())\n",
    "\n",
    "data[\"first_air_date\"] = data[\"first_air_date\"].apply(lambda x: int(x[0:4]))\n",
    "data[\"last_air_date\"] = data[\"last_air_date\"].apply(lambda x: int(x[0:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling Numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using min-max scaling to scale between 0 and 1\n",
    "data['vote_average'] = (data['vote_average'] - data['vote_average'].min()) / (data['vote_average'].max() - data['vote_average'].min())\n",
    "data['vote_count'] = (data['vote_count'] - data['vote_count'].min()) / (data['vote_count'].max() - data['vote_count'].min())\n",
    "data['first_air_date'] = (data['first_air_date'] - data['first_air_date'].min()) / (data['first_air_date'].max() - data['first_air_date'].min())\n",
    "data['last_air_date'] = (data['last_air_date'] - data['last_air_date'].min()) / (data['last_air_date'].max() - data['last_air_date'].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting singular value coluns to list too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"original_language\"] = data[\"original_language\"].apply(lambda x: [x])\n",
    "data[\"type\"] = data[\"type\"].apply(lambda x: [x])\n",
    "data[\"origin_country\"] = data[\"origin_country\"].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new Column 'tags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tags\"] = data[\"overview\"]+data[\"genres\"]+data[\"tagline\"]+data[\"production_companies\"]+data[\"production_countries\"]+data[\"spoken_languages\"]+data[\"type\"]+data[\"original_language\"]+data['created_by']+data['origin_country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns which were used in making tags column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['overview', 'adult', 'type', 'tagline', 'genres', 'created_by', 'languages', 'origin_country', 'spoken_languages', 'production_companies', 'production_countries', 'original_language'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking a random Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           137045\n",
       "name                                                Tokyo 24th Ward\n",
       "vote_count                                                      0.0\n",
       "vote_average                                               0.419355\n",
       "first_air_date                                             0.975904\n",
       "last_air_date                                              0.971831\n",
       "poster_path                        /3NYB8HfKALKQ4cHGx8Rx4Dhd0YE.jpg\n",
       "tags              [The, Far, Eastern, Special, Administrative, R...\n",
       "Name: 15626, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting tags from list to string and converting it to all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tags\"] = data[\"tags\"].apply(lambda x: \" \".join(x))\n",
    "data[\"tags\"] = data[\"tags\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using stem to convert words with same parent noun, as the same word\n",
    "#### Eg. [Loved, Loves, Loving] will be converted to Love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tags\"]=data[\"tags\"].apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing using Term Frequency - Inverse Document Frequency to calculate word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "addon = data[['first_air_date', 'last_air_date', 'vote_average']]\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=12000, stop_words='english')\n",
    "vec = tfidf.fit_transform(data['tags'])\n",
    "\n",
    "combined_matrix = hstack([vec, addon])\n",
    "combined_matrix = combined_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 12003)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similarity matrix using cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim = cosine_similarity(combined_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the similarity matrix into a CSV file after sorting the rows in descending order and find top 20 similar tv shows indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open a new CSV file in write mode with UTF-8 encoding\n",
    "with open('sorted_lists_tv.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    for a in sim:\n",
    "       \n",
    "        ml = sorted(list(enumerate(a)), reverse=True, key=lambda x: x[1])[1:21]\n",
    "\n",
    "        row = [index for index, similarity in ml]\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing Index into a CSV for accessing id, name, poster from the index, stored in similarity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['id','name','poster_path']].to_csv('tvindex.csv',index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
